{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjxYWXIZKuI8ZGmnJ34vLg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivekp12/dst-group-project-2/blob/main/MarkM%5CSwish_research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Investigation of Swish\n",
        "\n",
        "In this section, we will investigate the Swish Activation function. The document is structured as follows.\n",
        "\n",
        "**Table of Contents**\n",
        "- [1. Requirements](#1-requirements)\n",
        "    - [1.1 Data Augmentation](#11-data-augmentation)\n",
        "    - [1.2 Train and Test splitting](#12-checking-for-duplicates)\n",
        "    - [1.3 Train:Validation split](#13-train-validation-split)\n",
        "- [2. Investigation](#2-investigation)\n",
        "    - [2.1 Introduction to Swish Activation Function](#21-introduction-to-swish)\n",
        "    - [2.2 Parameter-Specific Evaluations](#21-parameter-specific-evaluations)\n",
        "    - [2.3 Additional Techniques and Enhancements](#22-additional-techniques-and-enhancements)\n",
        "- [3. Final Model Testing](#3-model-testing)\n",
        "- [4. Conclusion](#4-conclusion)\n",
        "- [5. References](#5-references)\n",
        "\n"
      ],
      "metadata": {
        "id": "lQYQinfAzBQb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Requirements\n",
        "\n",
        "This section outlines the preprocessing pipleine that we impliment for consistency. Here, we download the data, run the preprocessing script and then run the ImageDataGen which impliments augmentation with geometric transformations (i.e flips, shears, rotations, zooms etc, and brightness, contrast changes) as outlined in our exploratory data analysis.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZchQBBWj3Zov"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.1 Data Augmentation\n",
        "\n"
      ],
      "metadata": {
        "id": "Wyu6Mto34V-v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEC4LdLEUE39",
        "outputId": "e1a8ee3d-1ec7-4afd-a8b6-bb8596ce6235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/masoudnickparvar/brain-tumor-mri-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 149M/149M [00:02<00:00, 54.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/masoudnickparvar/brain-tumor-mri-dataset/versions/1\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path  # Import pathlib to work with paths\n",
        "import kagglehub\n",
        "import os  # Import os module for file operations\n",
        "import hashlib\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import os\n",
        "import imutils\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"masoudnickparvar/brain-tumor-mri-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# Convert path to a Path object\n",
        "path = Path(path)\n",
        "\n",
        "# Define your project directory and labels based on your dataset structure\n",
        "PROJECT_DIR = path\n",
        "LABELS = ['pituitary', 'notumor', 'meningioma', 'glioma']  # Adjust these labels based on your dataset's folder names\n",
        "\n",
        "def crop_img(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
        "    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
        "    thresh = cv2.erode(thresh, None, iterations=2)\n",
        "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
        "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnts = imutils.grab_contours(cnts)\n",
        "    c = max(cnts, key=cv2.contourArea)\n",
        "    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
        "    extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
        "    extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
        "    extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
        "    ADD_PIXELS = 0\n",
        "    new_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()\n",
        "    return new_img\n",
        "\n",
        "\n",
        "# Convert 'path' to Path object (already done above)\n",
        "train_dir = path / \"Training\"\n",
        "test_dir = path / \"Testing\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    training = train_dir\n",
        "    testing = test_dir\n",
        "\n",
        "    training_dir = os.listdir(training)\n",
        "    testing_dir = os.listdir(testing)\n",
        "\n",
        "    IMG_SIZE = 256\n",
        "\n",
        "    for dir in training_dir:\n",
        "        save_path = Path('cleaned/Training') / dir  # Using pathlib's '/' operator\n",
        "        path = training / dir  # Using pathlib's '/' operator\n",
        "        image_dir = os.listdir(path)\n",
        "\n",
        "        for img in image_dir:\n",
        "            image = cv2.imread(str(path / img))  # Convert Path to string for OpenCV\n",
        "            new_img = crop_img(image)\n",
        "            new_img = cv2.resize(new_img, (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "            if not save_path.exists():\n",
        "                save_path.mkdir(parents=True)\n",
        "\n",
        "            cv2.imwrite(str(save_path / img), new_img)  # Convert Path to string for OpenCV\n",
        "\n",
        "    for dir in testing_dir:\n",
        "        save_path = Path('cleaned/Testing') / dir\n",
        "        path = testing / dir\n",
        "        image_dir = os.listdir(path)\n",
        "\n",
        "        for img in image_dir:\n",
        "            image = cv2.imread(str(path / img))\n",
        "            new_img = crop_img(image)\n",
        "            new_img = cv2.resize(new_img, (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "            if not save_path.exists():\n",
        "                save_path.mkdir(parents=True)\n",
        "\n",
        "            cv2.imwrite(str(save_path / img), new_img)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.2 Train and Test Splitting"
      ],
      "metadata": {
        "id": "3EFCRFL94h51"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIJCs6PJUE3-",
        "outputId": "98c51a39-4fc0-49a9-a73c-b26e6bd54453"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5712 images belonging to 4 classes.\n",
            "Found 1311 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define directories for training and testing images\n",
        "train_dir = Path('cleaned/Training')\n",
        "test_dir = Path('cleaned/Testing')\n",
        "\n",
        "# Number of classes\n",
        "LABELS = ['pituitary', 'notumor', 'meningioma', 'glioma']\n",
        "\n",
        "# Image size and batch size\n",
        "IMG_SIZE = 64  # Resize images to 64x64\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Setup ImageDataGenerators for loading and preprocessing the images\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,  # Normalize pixel values to [0, 1]\n",
        "    rotation_range=20,  # Random rotation\n",
        "    width_shift_range=0.1,  # Horizontal shift\n",
        "    height_shift_range=0.1,  # Vertical shift\n",
        "    shear_range=0.2,  # Shear transformation\n",
        "    zoom_range=0.2,  # Zoom in and out\n",
        "    horizontal_flip=True,  # Flip horizontally\n",
        "    fill_mode='nearest',  # Fill any missing pixels using the nearest pixel\n",
        "    brightness_range=(0.5, 1.5),  # Randomly adjust brightness between 0.5 and 1.5 times the original\n",
        "    channel_shift_range=20.0  # Randomly shift RGB channels (intensity)\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0)  # Only rescale for test data\n",
        "\n",
        "# Load images from directories using ImageDataGenerator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),  # Resize images to 64x64\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',  # Use 'binary' for binary classification, 'categorical' otherwise\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),  # Resize images to 64x64\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False  # Do not shuffle for test data\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.3 Train:Validation split\n",
        "\n",
        "To fine-tune hyperparameters and assess their impact on performance, we will split the training data into training and validation sets. There are many factors that can influence the choice of split such as data availability and model complexity. If the validation split is too large, then the remaining training data will be substantially smaller than the entire training set and so the model may not be trained on a sufficient volume of data for convergence of performance on training data. On the other hand, if the validation split is too small, hyperparameter tuning becomes more difficult and the incites we gain become less reliable meaning that we may choose a suboptimal model that does not translate to a higher performance in testing [1]. Various splits are listed below.\n",
        "\n",
        "1.\n",
        "\n",
        "2.\n",
        "\n",
        "3.\n"
      ],
      "metadata": {
        "id": "V653WTAX5xWb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cMwstBLx52fE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. References\n",
        "\n",
        "[1] https://millengustavo.github.io/handson-ml/ - for validation split"
      ],
      "metadata": {
        "id": "NoUWIfg_6tSm"
      }
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "<big> Still a draft. </big>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In today’s digital age, the amount of data generated is reaching unprecedented levels [2]. The ability to analyze and extract meaningful insights from large and diverse datasets, commonly referred to as \"big data\" [1], has become essential. The emergence of big data is driven by technological advancements and societal shifts. An example of big data is the tracking of consumer behavior to deliver hyper-personalized recommendations.\n",
    "\n",
    "To remain competitive in today’s data-driven landscape, organizations in various fields, such as retail, healthcare and finance [3], are increasingly adopting advanced data science techniques to leverage the power of big data. Studying the way data science techniques can be applied to data at scale is therefore a topic which garners much interest. This project aims to explore the application of Massively Parallel Data Science technologies to address a significant scientific question within a chosen domain [**WHICH QUESTION? WHICH DOMAIN?**]. By harnessing technologies such as GPU parallelism, we aspire to unlock the potential hidden within vast amounts of data.\n",
    "\n",
    "The focus of this project will be on a specific application domain [**WHICH QUESTION? WHICH DOMAIN?**], where we will formulate an analysis question that not only reflects the complexities of real-world data but also tests the limits of current computational methodologies [WHICH QUESTION?]. We will employ a variety of data science techniques, including traditional classifiers, neural networks, and exploratory data analysis, to investigate this question. Our approach will incorporate both the theoretical foundations and practical implementations of these methods, evaluating their performance through rigorous computational strategies.\n",
    "\n",
    "Furthermore, we will emphasize the significance of scalability in our analysis. As data volumes continue to surge, it is essential to develop solutions that can efficiently process and analyze data at scale. By leveraging technologies such as [PySpark and] GPU-based parallelism, we aim to demonstrate how our chosen models would perform in high-volume environments, preparing us for the challenges of real-world data science applications.\n",
    "\n",
    "Ultimately, this project seeks to contribute to the understanding of how Massively Parallel Data Science techniques can be effectively applied to extract insights from complex datasets, paving the way for enhanced decision-making and innovation in our chosen field.\n",
    "\n",
    "# References\n",
    "\n",
    "[1] https://cloud.google.com/learn/what-is-big-data\n",
    "\n",
    "[2] Source saying that over 400 million terabyes of data is generated per day. https://explodingtopics.com/blog/data-generated-per-day\n",
    "\n",
    "[3] https://www.icas.com/news/10-companies-using-big-data"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
